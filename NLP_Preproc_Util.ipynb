{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLP_Preproc_Util.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/itspritish/nlp/blob/master/NLP_Preproc_Util.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q-LFEAg87AxW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import re\n",
        "import csv\n",
        "import codecs\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.layers import Dense, Input, LSTM, Embedding, Dropout, Activation,Lambda\n",
        "from keras.layers.merge import concatenate\n",
        "from keras.models import Model,Sequential\n",
        "from sklearn.model_selection import train_test_split "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TDpEK9YYFRFK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = pd.read_csv('drive/My Drive/dataml/quora_duplicate_questions.csv')\n",
        "data = data.applymap(str)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n2HdrQGBzFa0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gd5yGtxqii6K",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "155d90b8-10a9-4a99-b6f6-7be235fb017a"
      },
      "source": [
        "data.head()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>qid1</th>\n",
              "      <th>qid2</th>\n",
              "      <th>question1</th>\n",
              "      <th>question2</th>\n",
              "      <th>is_duplicate</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>What is the step by step guide to invest in sh...</td>\n",
              "      <td>What is the step by step guide to invest in sh...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>What is the story of Kohinoor (Koh-i-Noor) Dia...</td>\n",
              "      <td>What would happen if the Indian government sto...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>6</td>\n",
              "      <td>How can I increase the speed of my internet co...</td>\n",
              "      <td>How can Internet speed be increased by hacking...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>7</td>\n",
              "      <td>8</td>\n",
              "      <td>Why am I mentally very lonely? How can I solve...</td>\n",
              "      <td>Find the remainder when [math]23^{24}[/math] i...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>9</td>\n",
              "      <td>10</td>\n",
              "      <td>Which one dissolve in water quikly sugar, salt...</td>\n",
              "      <td>Which fish would survive in salt water?</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id  qid1  ...                                          question2 is_duplicate\n",
              "0   0     1  ...  What is the step by step guide to invest in sh...            0\n",
              "1   1     3  ...  What would happen if the Indian government sto...            0\n",
              "2   2     5  ...  How can Internet speed be increased by hacking...            0\n",
              "3   3     7  ...  Find the remainder when [math]23^{24}[/math] i...            0\n",
              "4   4     9  ...            Which fish would survive in salt water?            0\n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4feLUkFUXjHY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X1 = data['question1'].tolist()\n",
        "X = data['question1'].tolist()\n",
        "X2 = data['question2'].tolist()\n",
        "X.extend(data['question2'].tolist())\n",
        "\n",
        "\n",
        "y = data['is_duplicate'].tolist()\n",
        "\n",
        "X1_train, X1_test, X2_train, X2_test, y_train, y_test = train_test_split(X1, X2, y, test_size=0.33)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mTSPPOATo4g2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "outputId": "f0b77967-c6e4-47da-94fe-7e3299b2b9bd"
      },
      "source": [
        "\"\"\"tokenizer = Tokenizer(nb_words=1000)\n",
        "texts ={}\n",
        "try:\n",
        "  texts = tokenizer.fit_on_texts(X)\n",
        "  #sequences = tokenizer.texts_to_sequences(X)\n",
        "  print(sequences)\n",
        "except Exception as e:\n",
        "  print('Exception is', e)  \"\"\"\n"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras_preprocessing/text.py:178: UserWarning: The `nb_words` argument in `Tokenizer` has been renamed `num_words`.\n",
            "  warnings.warn('The `nb_words` argument in `Tokenizer` '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7TN3VLZ2QjqE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "texts"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ljwkjG38PmP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import operator \n",
        "def check_coverage(vocab,embeddings_index):\n",
        "    a = {}\n",
        "    oov = {}\n",
        "    k = 0\n",
        "    i = 0\n",
        "    for word in tqdm(vocab):\n",
        "        try:\n",
        "            a[word] = embeddings_index[word]\n",
        "            k += vocab[word]\n",
        "        except:\n",
        "\n",
        "            oov[word] = vocab[word]\n",
        "            i += vocab[word]\n",
        "            pass\n",
        "\n",
        "    print('Found embeddings for {:.2%} of vocab'.format(len(a) / len(vocab)))\n",
        "    print('Found embeddings for  {:.2%} of all text'.format(k / (k + i)))\n",
        "    sorted_x = sorted(oov.items(), key=operator.itemgetter(1))[::-1]\n",
        "\n",
        "    return sorted_x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xhCL5tX78bOY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tqdm import tqdm\n",
        "def build_vocab(sentences, verbose =  True):\n",
        "    \"\"\"\n",
        "    :param sentences: list of list of words\n",
        "    :return: dictionary of words and their count\n",
        "    \"\"\"\n",
        "    vocab = {}\n",
        "    for sentence in tqdm(sentences, disable = (not verbose)):\n",
        "        for word in sentence.split():\n",
        "            try:\n",
        "                vocab[word] += 1\n",
        "            except KeyError:\n",
        "                vocab[word] = 1\n",
        "    return vocab"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XFHcUvIlM3Op",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vocab = build_vocab(X)\n",
        "word2index, embedding_matrix = load_glove_embeddings('drive/My Drive/dataml/glove.6B.50d.txt', embedding_dim=50)\n",
        "oov = check_coverage(vocab,word2index)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J2ZHi0LA9B0R",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "15adfb2d-3bf2-4f3c-fabd-ee985e3dad08"
      },
      "source": [
        "oov[500:600]"
      ],
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Cyrus', 459),\n",
              " ('C++?', 459),\n",
              " ('videos?', 458),\n",
              " ('note?', 458),\n",
              " ('it,', 457),\n",
              " (\"haven't\", 457),\n",
              " ('Hill-station', 456),\n",
              " ('thing?', 455),\n",
              " ('not,', 455),\n",
              " ('data?', 454),\n",
              " ('parents?', 454),\n",
              " ('State', 454),\n",
              " ('College', 454),\n",
              " ('OS', 452),\n",
              " ('IQ?', 452),\n",
              " ('end?', 451),\n",
              " ('beginners?', 450),\n",
              " (\"what's\", 450),\n",
              " ('email?', 449),\n",
              " ('management?', 446),\n",
              " ('Lord', 446),\n",
              " ('RBI', 446),\n",
              " ('3G', 444),\n",
              " ('Somme,', 442),\n",
              " ('Hitler', 441),\n",
              " ('WhatsApp?', 441),\n",
              " ('Kashmir', 441),\n",
              " ('power?', 439),\n",
              " ('life,', 436),\n",
              " ('degree?', 436),\n",
              " ('investment?', 433),\n",
              " ('Bill', 433),\n",
              " ('League', 432),\n",
              " ('Russian', 431),\n",
              " ('International', 431),\n",
              " ('jobs?', 430),\n",
              " ('1?', 430),\n",
              " ('cancer?', 430),\n",
              " ('PAN', 429),\n",
              " ('created?', 429),\n",
              " ('War?', 429),\n",
              " ('WiFi', 428),\n",
              " ('Islam?', 428),\n",
              " ('Kerala?', 428),\n",
              " ('works?', 427),\n",
              " ('accounts?', 427),\n",
              " ('Islam', 427),\n",
              " ('Chennai?', 426),\n",
              " ('first?', 426),\n",
              " ('Minister', 425),\n",
              " ('society?', 424),\n",
              " ('Khan', 424),\n",
              " ('song?', 423),\n",
              " ('Korean', 422),\n",
              " ('Wars', 422),\n",
              " ('age?', 420),\n",
              " ('Singapore', 420),\n",
              " ('field?', 420),\n",
              " ('Data', 420),\n",
              " (\"one's\", 420),\n",
              " ('abroad?', 418),\n",
              " ('California?', 417),\n",
              " ('education?', 417),\n",
              " ('religion?', 416),\n",
              " ('Please', 416),\n",
              " ('Gold', 415),\n",
              " ('Spanish', 414),\n",
              " ('well?', 412),\n",
              " ('DC', 411),\n",
              " ('answer?', 410),\n",
              " ('(in', 410),\n",
              " ('state?', 409),\n",
              " ('answers?', 407),\n",
              " ('Note', 407),\n",
              " ('Kerala', 406),\n",
              " ('disorder?', 406),\n",
              " ('East', 405),\n",
              " ('C?', 404),\n",
              " ('White', 403),\n",
              " ('movie)?', 403),\n",
              " ('Harvard', 403),\n",
              " ('application?', 402),\n",
              " ('go?', 401),\n",
              " ('CGL', 400),\n",
              " ('Moto', 399),\n",
              " ('buy?', 399),\n",
              " ('Pokemon', 398),\n",
              " ('products?', 397),\n",
              " ('child?', 396),\n",
              " ('live?', 393),\n",
              " ('family?', 393),\n",
              " ('beginner?', 392),\n",
              " ('children?', 392),\n",
              " ('place?', 392),\n",
              " ('together?', 392),\n",
              " ('process?', 391),\n",
              " ('Reliance', 390),\n",
              " ('USB', 390),\n",
              " ('QuickBooks', 390),\n",
              " ('flat?', 388)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UlB410uOrpP9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UW9xkOKWXDBn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\"\"\"\n",
        "https://gist.github.com/jovianlin/load_glove_embeddings.py\n",
        "\"\"\"\n",
        "\n",
        "def load_glove_embeddings(fp, embedding_dim, include_empty_char=True):\n",
        "    \"\"\"\n",
        "    Loads pre-trained word embeddings (GloVe embeddings)\n",
        "        Inputs: - fp: filepath of pre-trained glove embeddings\n",
        "                - embedding_dim: dimension of each vector embedding\n",
        "                - generate_matrix: whether to generate an embedding matrix\n",
        "        Outputs:\n",
        "                - word2coefs: Dictionary. Word to its corresponding coefficients\n",
        "                - word2index: Dictionary. Word to word-index\n",
        "                - embedding_matrix: Embedding matrix for Keras Embedding layer\n",
        "    \"\"\"\n",
        "    # First, build the \"word2coefs\" and \"word2index\"\n",
        "    word2coefs = {} # word to its corresponding coefficients\n",
        "    word2index = {} # word to word-index\n",
        "    with open(fp) as f:\n",
        "        for idx, line in enumerate(f):\n",
        "            try:\n",
        "                data = [x.strip().lower() for x in line.split()]\n",
        "                word = data[0]\n",
        "                coefs = np.asarray(data[1:embedding_dim+1], dtype='float32')\n",
        "                word2coefs[word] = coefs\n",
        "                if word not in word2index:\n",
        "                    word2index[word] = len(word2index)\n",
        "            except Exception as e:\n",
        "                print('Exception occurred in `load_glove_embeddings`:', e)\n",
        "                continue\n",
        "        # End of for loop.\n",
        "    # End of with open\n",
        "    if include_empty_char:\n",
        "        word2index[''] = len(word2index)\n",
        "    # Second, build the \"embedding_matrix\"\n",
        "    # Words not found in embedding index will be all-zeros. Hence, the \"+1\".\n",
        "    vocab_size = len(word2coefs)+1 if include_empty_char else len(word2coefs)\n",
        "    embedding_matrix = np.zeros((vocab_size, embedding_dim))\n",
        "    for word, idx in word2index.items():\n",
        "        embedding_vec = word2coefs.get(word)\n",
        "        if embedding_vec is not None and embedding_vec.shape[0]==embedding_dim:\n",
        "            embedding_matrix[idx] = np.asarray(embedding_vec)\n",
        "    # return word2coefs, word2index, embedding_matrix\n",
        "    return word2index, np.asarray(embedding_matrix)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}